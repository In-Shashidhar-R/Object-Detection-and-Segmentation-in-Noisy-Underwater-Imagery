{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2565747,"sourceType":"datasetVersion","datasetId":1557385}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import the Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:06:51.329614Z","iopub.execute_input":"2025-03-09T15:06:51.329885Z","iopub.status.idle":"2025-03-09T15:07:04.136697Z","shell.execute_reply.started":"2025-03-09T15:06:51.329856Z","shell.execute_reply":"2025-03-09T15:07:04.135760Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Step 1: Build U-Net Model\nIn this step, we will define the architecture of the U-Net model. The U-Net consists of an encoder, bottleneck, and decoder. We will use convolutional layers to extract features, max-pooling layers to downsample, and transpose convolutions for upsampling. Finally, the model will output a binary mask.\n","metadata":{}},{"cell_type":"code","source":"def build_unet(input_shape=(256, 256, 3)):\n    inputs = Input(input_shape)\n    \n    # Encoder\n    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n    p1 = MaxPooling2D((2, 2))(c1)\n    \n    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n    p2 = MaxPooling2D((2, 2))(c2)\n    \n    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n    p3 = MaxPooling2D((2, 2))(c3)\n    \n    # Bottleneck\n    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n    \n    # Decoder\n    u1 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n    u1 = concatenate([u1, c3])\n    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(u1)\n    \n    u2 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n    u2 = concatenate([u2, c2])\n    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n    \n    u3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n    u3 = concatenate([u3, c1])\n    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u3)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n    \n    model = Model(inputs, outputs)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:07:04.137993Z","iopub.execute_input":"2025-03-09T15:07:04.138477Z","iopub.status.idle":"2025-03-09T15:07:04.145842Z","shell.execute_reply.started":"2025-03-09T15:07:04.138453Z","shell.execute_reply":"2025-03-09T15:07:04.144833Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Step 2: Load Images and Masks\nIn this step, we load the training and testing images from the specified directories. The images and their corresponding binary masks are resized to a uniform size (256x256). The pixel values are normalized to a range between 0 and 1.\n","metadata":{}},{"cell_type":"code","source":"image_dir = '/kaggle/input/semantic-segmentation-of-underwater-imagery-suim/train_val/images/'\nmask_dir = '/kaggle/input/semantic-segmentation-of-underwater-imagery-suim/train_val/masks/'\n\nimages = []\nmasks = []\n\nfor filename in os.listdir(image_dir):\n    if filename.endswith('.jpg'):\n        image = cv2.imread(os.path.join(image_dir, filename))\n        image = cv2.resize(image, (256, 256)) / 255.0\n        mask = cv2.imread(os.path.join(mask_dir, filename.replace('.jpg', '.bmp')), 0)\n        mask = cv2.resize(mask, (256, 256)) / 255.0\n        \n        images.append(image)\n        masks.append(mask)\n\n# Convert to NumPy Arrays\nX = np.array(images)\nY = np.expand_dims(np.array(masks), axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:07:04.147445Z","iopub.execute_input":"2025-03-09T15:07:04.147672Z","iopub.status.idle":"2025-03-09T15:07:50.703681Z","shell.execute_reply.started":"2025-03-09T15:07:04.147652Z","shell.execute_reply":"2025-03-09T15:07:50.703001Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Step 3: Split Data and Train\nIn this step, we split the dataset into training and testing sets (90% training, 10% testing). Then, we train the U-Net model on the training data for 10 epochs. The model is compiled with the Adam optimizer and binary cross-entropy loss.\n","metadata":{}},{"cell_type":"code","source":"unet_model = build_unet()\nunet_model.fit(X, Y, epochs=10, batch_size=16, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:07:50.704735Z","iopub.execute_input":"2025-03-09T15:07:50.704999Z","iopub.status.idle":"2025-03-09T15:10:58.791023Z","shell.execute_reply.started":"2025-03-09T15:07:50.704974Z","shell.execute_reply":"2025-03-09T15:10:58.790200Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 229ms/step - accuracy: 0.3365 - loss: 0.6560\nEpoch 2/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3439 - loss: 0.6457\nEpoch 3/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3336 - loss: 0.6416\nEpoch 4/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3266 - loss: 0.6429\nEpoch 5/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3354 - loss: 0.6371\nEpoch 6/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3306 - loss: 0.6397\nEpoch 7/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3276 - loss: 0.6444\nEpoch 8/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3441 - loss: 0.6321\nEpoch 9/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3379 - loss: 0.6320\nEpoch 10/10\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 162ms/step - accuracy: 0.3581 - loss: 0.6262\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x78b0140f5240>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### Step 4: Save the Model\nAfter training the model, we save it to the `/kaggle/working/` directory. This allows us to use the trained model for inference on the test data.\n","metadata":{}},{"cell_type":"code","source":"unet_model.save('/kaggle/working/best_model.keras')\nprint(\"✅ Model trained and saved as best_model.keras.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:10:58.791982Z","iopub.execute_input":"2025-03-09T15:10:58.792290Z","iopub.status.idle":"2025-03-09T15:10:59.028761Z","shell.execute_reply.started":"2025-03-09T15:10:58.792268Z","shell.execute_reply":"2025-03-09T15:10:59.028007Z"}},"outputs":[{"name":"stdout","text":"✅ Model trained and saved as best_model.keras.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Load Test Images and Masks\nIn this step, we load the test images and their corresponding binary masks from the specified directories. The images are resized to the required shape (256x256) and normalized. Similarly, the masks are resized and normalized as well.\n","metadata":{}},{"cell_type":"code","source":"test_image_dir = '/kaggle/input/semantic-segmentation-of-underwater-imagery-suim/TEST/images'\ntest_mask_dir = '/kaggle/input/semantic-segmentation-of-underwater-imagery-suim/TEST/masks'\n\ntest_images = []\ntest_masks = []\n\nfor filename in os.listdir(test_image_dir):\n    if filename.endswith('.jpg'):\n        image = cv2.imread(os.path.join(test_image_dir, filename))\n        image = cv2.resize(image, (256, 256)) / 255.0\n        mask = cv2.imread(os.path.join(test_mask_dir, filename.replace('.jpg', '.bmp')), 0)\n        mask = cv2.resize(mask, (256, 256)) / 255.0\n        \n        test_images.append(image)\n        test_masks.append(mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:11:35.001845Z","iopub.execute_input":"2025-03-09T15:11:35.002182Z","iopub.status.idle":"2025-03-09T15:11:35.660830Z","shell.execute_reply.started":"2025-03-09T15:11:35.002158Z","shell.execute_reply":"2025-03-09T15:11:35.660176Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Step 5: Predict and Save Results\nIn this step, we use the trained model to predict segmentation masks for the test images. We calculate the Intersection over Union (IoU), Dice coefficient, and accuracy for each image, and save the results as images.\n","metadata":{}},{"cell_type":"code","source":"output_dir = '/kaggle/working/results/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\ntotal_images = len(test_images)\ncurrent_image = 0\n\nfor i in range(len(test_images)):\n    current_image += 1\n    \n    # Predict using U-Net\n    pred_mask = unet_model.predict(np.expand_dims(test_images[i], axis=0))\n    pred_mask = (pred_mask > 0.5).astype(np.uint8)[0, :, :, 0]\n    \n    # Calculate Metrics\n    gt_mask = (test_masks[i] > 0).astype(np.uint8)\n    intersection = np.sum((pred_mask == 1) & (gt_mask == 1))\n    union = np.sum((pred_mask == 1) | (gt_mask == 1))\n    \n    iou = intersection / union\n    dice = (2 * intersection) / (np.sum(pred_mask == 1) + np.sum(gt_mask == 1))\n    accuracy = np.sum(pred_mask == gt_mask) / gt_mask.size\n\n    # ✅ Now correctly plot the images\n    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n    ax[0].imshow(test_images[i])\n    ax[0].set_title(\"Original Image\")\n    \n    ax[1].imshow(gt_mask, cmap='gray')\n    ax[1].set_title(\"Ground Truth\")\n    \n    ax[2].imshow(pred_mask, cmap='gray')\n    ax[2].set_title(f\"IoU: {iou:.4f}, Dice: {dice:.4f}, Acc: {accuracy:.4f}\")\n    \n    # ✅ Save the image with metrics\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, f'image_{i+1}.png'))\n    plt.close()\n    \n    # ✅ Show progress in terminal\n    print(f\"✅ Processed {current_image}/{total_images} | IoU: {iou:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:12:37.377547Z","iopub.execute_input":"2025-03-09T15:12:37.377874Z","iopub.status.idle":"2025-03-09T15:13:52.420036Z","shell.execute_reply.started":"2025-03-09T15:12:37.377852Z","shell.execute_reply":"2025-03-09T15:13:52.419196Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n✅ Processed 1/110 | IoU: 0.1539\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 2/110 | IoU: 0.4919\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 3/110 | IoU: 0.7342\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 4/110 | IoU: 0.8532\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 5/110 | IoU: 0.5309\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 6/110 | IoU: 0.3002\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n✅ Processed 7/110 | IoU: 0.6360\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 8/110 | IoU: 0.0018\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 9/110 | IoU: 0.2882\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n✅ Processed 10/110 | IoU: 0.0929\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 11/110 | IoU: 0.0001\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 12/110 | IoU: 0.4244\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 13/110 | IoU: 0.1596\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 14/110 | IoU: 0.6892\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n✅ Processed 15/110 | IoU: 0.7762\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n✅ Processed 16/110 | IoU: 0.8881\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 17/110 | IoU: 0.5271\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 18/110 | IoU: 0.7030\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 19/110 | IoU: 0.7944\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 20/110 | IoU: 0.7033\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 21/110 | IoU: 0.2934\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 22/110 | IoU: 0.9661\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n✅ Processed 23/110 | IoU: 0.0143\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 24/110 | IoU: 0.6175\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 25/110 | IoU: 0.4796\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 26/110 | IoU: 0.1410\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 27/110 | IoU: 0.6192\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 28/110 | IoU: 0.3149\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 29/110 | IoU: 0.1366\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 30/110 | IoU: 0.7879\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 31/110 | IoU: 0.7576\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 32/110 | IoU: 0.8200\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 33/110 | IoU: 0.6458\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 34/110 | IoU: 0.8869\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 35/110 | IoU: 0.9693\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 36/110 | IoU: 0.6880\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 37/110 | IoU: 0.8575\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 38/110 | IoU: 0.6922\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n✅ Processed 39/110 | IoU: 0.6289\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 40/110 | IoU: 0.5954\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 41/110 | IoU: 0.7149\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 42/110 | IoU: 0.4594\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 43/110 | IoU: 0.4555\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 44/110 | IoU: 0.9239\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 45/110 | IoU: 0.9468\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 46/110 | IoU: 0.3572\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 47/110 | IoU: 0.9388\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 48/110 | IoU: 0.3292\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 49/110 | IoU: 0.8781\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 50/110 | IoU: 0.4705\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 51/110 | IoU: 0.8349\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 52/110 | IoU: 0.7134\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n✅ Processed 53/110 | IoU: 0.5924\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 54/110 | IoU: 0.5969\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 55/110 | IoU: 0.8198\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 56/110 | IoU: 0.1020\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 57/110 | IoU: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 58/110 | IoU: 0.1986\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 59/110 | IoU: 0.1796\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 60/110 | IoU: 0.0623\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n✅ Processed 61/110 | IoU: 0.4871\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 62/110 | IoU: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 63/110 | IoU: 0.8949\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 64/110 | IoU: 0.8254\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 65/110 | IoU: 0.7248\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 66/110 | IoU: 0.5964\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 67/110 | IoU: 0.4045\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 68/110 | IoU: 0.8356\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 69/110 | IoU: 0.7052\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 70/110 | IoU: 0.0997\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 71/110 | IoU: 0.3722\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 72/110 | IoU: 0.2299\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 73/110 | IoU: 0.7417\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 74/110 | IoU: 0.8893\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 75/110 | IoU: 0.3102\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 76/110 | IoU: 0.9218\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 77/110 | IoU: 0.4727\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 78/110 | IoU: 0.4885\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 79/110 | IoU: 0.9100\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 80/110 | IoU: 0.5569\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 81/110 | IoU: 0.5950\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 82/110 | IoU: 0.0433\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n✅ Processed 83/110 | IoU: 0.2704\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 84/110 | IoU: 0.4592\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 85/110 | IoU: 0.4722\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 86/110 | IoU: 0.3174\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n✅ Processed 87/110 | IoU: 0.7286\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 88/110 | IoU: 0.2137\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 89/110 | IoU: 0.2199\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 90/110 | IoU: 0.6568\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 91/110 | IoU: 0.5770\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 92/110 | IoU: 0.6428\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 93/110 | IoU: 0.9115\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 94/110 | IoU: 0.1497\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 95/110 | IoU: 0.3456\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n✅ Processed 96/110 | IoU: 0.3855\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 97/110 | IoU: 0.6765\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 98/110 | IoU: 0.1765\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 99/110 | IoU: 0.9084\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 100/110 | IoU: 0.0820\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n✅ Processed 101/110 | IoU: 0.6815\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 102/110 | IoU: 0.5876\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 103/110 | IoU: 0.3149\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 104/110 | IoU: 0.2630\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 105/110 | IoU: 0.5613\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 106/110 | IoU: 0.8256\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 107/110 | IoU: 0.4257\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n✅ Processed 108/110 | IoU: 0.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 109/110 | IoU: 0.6906\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n✅ Processed 110/110 | IoU: 0.0032\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### Step 6: Final Progress Message\nAfter processing all images, we will print a message indicating that all images have been processed successfully.\n","metadata":{}},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/results', 'zip', '/kaggle/working/results')\nprint(\"✅ All 110 test images processed. Download results.zip\")\nfrom IPython.display import FileLink\nFileLink('/kaggle/working/results.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:14:50.509679Z","iopub.execute_input":"2025-03-09T15:14:50.510064Z","iopub.status.idle":"2025-03-09T15:14:52.007649Z","shell.execute_reply.started":"2025-03-09T15:14:50.510033Z","shell.execute_reply":"2025-03-09T15:14:52.006998Z"}},"outputs":[{"name":"stdout","text":"✅ All 110 test images processed. Download results.zip\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/results.zip","text/html":"<a href='/kaggle/working/results.zip' target='_blank'>/kaggle/working/results.zip</a><br>"},"metadata":{}}],"execution_count":11}]}